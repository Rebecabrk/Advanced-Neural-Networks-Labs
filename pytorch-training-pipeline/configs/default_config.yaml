# --- PyTorch Training Pipeline Default Configuration ---

# CUSTOMIZABLE PARAMETERS
# ----------------------------------------------------------------------
# 1. DATASET CONFIGURATION
# ----------------------------------------------------------------------
data:
  dataset_name: "MNIST" 
  data_augmentation: False 

# if data_augmentation is True also add a transforms mapping
# the mapping will contain only the transforms wanted
# example:
# transforms:
  # normalization:
  #   enabled: False
  #   mean: 
  #     default: [0.5, 0.5, 0.5]
  #     validator: list_float
  #   std: 
  #     default: [0.5, 0.5, 0.5]
  #     validator: list_float
  # random_horizontal_flip:
  # ......................
  #   see more available transforms in /configs/transforms.yaml

# ----------------------------------------------------------------------
# MODEL CONFIGURATION
# ----------------------------------------------------------------------
model:
  name: "MLP" 
  pretrained: False 
  # if MLP is chosen, also add mlp_params mapping
  # example: 
  mlp_params:
    hidden_layers: [1024, 512, 256]
    activation: ["ReLU", "ReLU", "Sigmoid"]
    dropout: 0.5

# ----------------------------------------------------------------------
# OPTIMIZER CONFIGURATION
# ----------------------------------------------------------------------
optimizer:
  name: "SGD" 
  lr: 0.001
  weight_decay: 0.01
  # each optimizer has its params mapping 
  sgd_params:
    momentum: 0.0
    dampening: 0.0
    nesterov: False


# ----------------------------------------------------------------------
# TRAINING PARAMETERS
# ----------------------------------------------------------------------
training:
  epochs: 10
  batch_size: 128 
  batch_scheduler: 
    enabled: False 
    schedule_epochs: [10, 25, 40]
    batch_size_increments: [128, 256, 512]
  early_stopping:
    enabled: False  
    patience: 10  

# ----------------------------------------------------------------------
# LEARNING RATE SCHEDULER CONFIGURATION
# ----------------------------------------------------------------------
lr_scheduler:
  enabled: False
  name: "StepLR" 
  step_size: 15
  gamma: 0.1

# NOT CUSTOMIZABLE
# ----------------------------------------------------------------------
# REPORTING AND LOGGING
# ----------------------------------------------------------------------
logging:
  reporter: "wandb" 
  project_name: "Advanced-NN-Assignment-3"
  run_name: "Default_MLP_SGD"
  log_interval_steps: 100

# ----------------------------------------------------------------------
# GLOBAL SETTINGS
# ----------------------------------------------------------------------
global:
  seed: 42
  device: "auto"    
  num_workers: 4     
  save_dir: "checkpoints" 
  report_dir: "logs" # tensorboard/wandb output